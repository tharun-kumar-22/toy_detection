{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d24f545",
   "metadata": {},
   "source": [
    "# Training the Faster RCNN model with resnet50 backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cca284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      " Starting training...\n",
      " Epoch 1/10 | Total Loss: 25.0001\n",
      " mAP@IoU=0.5: 0.9950 | mAP@IoU=0.5:0.95: 0.8527\n",
      " Epoch 2/10 | Total Loss: 7.4475\n",
      " mAP@IoU=0.5: 0.9950 | mAP@IoU=0.5:0.95: 0.9062\n",
      " Epoch 3/10 | Total Loss: 5.5346\n",
      " mAP@IoU=0.5: 0.9950 | mAP@IoU=0.5:0.95: 0.9301\n",
      " Epoch 4/10 | Total Loss: 4.6425\n",
      " mAP@IoU=0.5: 0.9950 | mAP@IoU=0.5:0.95: 0.9483\n",
      " Epoch 5/10 | Total Loss: 4.0596\n",
      " mAP@IoU=0.5: 0.9950 | mAP@IoU=0.5:0.95: 0.9111\n",
      " Epoch 6/10 | Total Loss: 3.9126\n",
      " mAP@IoU=0.5: 0.9950 | mAP@IoU=0.5:0.95: 0.9343\n",
      " Epoch 7/10 | Total Loss: 3.4913\n",
      " mAP@IoU=0.5: 0.9950 | mAP@IoU=0.5:0.95: 0.9614\n",
      " Epoch 8/10 | Total Loss: 3.0033\n",
      " mAP@IoU=0.5: 0.9950 | mAP@IoU=0.5:0.95: 0.9719\n",
      " Epoch 9/10 | Total Loss: 2.7801\n",
      " mAP@IoU=0.5: 0.9950 | mAP@IoU=0.5:0.95: 0.9689\n",
      " Epoch 10/10 | Total Loss: 2.6654\n",
      " mAP@IoU=0.5: 0.9950 | mAP@IoU=0.5:0.95: 0.9654\n",
      "Model saved as fasterrcnn_pascalvoc.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "\n",
    "# Config \n",
    "CLASSES = [\"__background__\", \"donkey\", \"tortoise\"]\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "# Force CPU to avoid CUDA loading issues\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(\"Using device:\", DEVICE)\n",
    "\n",
    "#VOC Dataset Loader\n",
    "class VOCDataset(Dataset):\n",
    "    def __init__(self, img_dir, ann_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.ann_dir = ann_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(img_dir) if f.endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.images[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_filename)\n",
    "        ann_path = os.path.join(self.ann_dir, os.path.splitext(img_filename)[0] + \".xml\")\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        w, h = image.size\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        tree = ET.parse(ann_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for obj in root.findall(\"object\"):\n",
    "            label = obj.find(\"name\").text\n",
    "            if label not in CLASSES:\n",
    "                continue\n",
    "            labels.append(CLASSES.index(label))\n",
    "\n",
    "            bbox = obj.find(\"bndbox\")\n",
    "            xmin = int(bbox.find(\"xmin\").text)\n",
    "            ymin = int(bbox.find(\"ymin\").text)\n",
    "            xmax = int(bbox.find(\"xmax\").text)\n",
    "            ymax = int(bbox.find(\"ymax\").text)\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.int64),\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "# Transforms\n",
    "def get_transform():\n",
    "    return ToTensor()\n",
    "\n",
    "\n",
    "root = \"C:/Users/anagh/OneDrive/Documents/MAI/S3/ACV/Toy_Data\"\n",
    "train_dataset = VOCDataset(\n",
    "    img_dir=os.path.join(root, \"train\", \"images\"),\n",
    "    ann_dir=os.path.join(root, \"train\", \"annotations\"),\n",
    "    transform=get_transform()\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# Load Faster R-CNN Model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "#Optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Training and Evaluation \n",
    "EPOCHS = 10\n",
    "#print(\" Starting training...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, targets in train_loader:\n",
    "        images = [img.to(DEVICE) for img in images]\n",
    "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\" Epoch {epoch+1}/{EPOCHS} | Total Loss: {total_loss:.4f}\")\n",
    "\n",
    "  \n",
    "    model.eval()\n",
    "    metric = MeanAveragePrecision()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in train_loader:\n",
    "            images = [img.to(DEVICE) for img in images]\n",
    "            outputs = model(images)\n",
    "            outputs = [{k: v.cpu() for k, v in t.items()} for t in outputs]\n",
    "            targets = [{k: v.cpu() for k, v in t.items()} for t in targets]\n",
    "            metric.update(outputs, targets)\n",
    "\n",
    "        results = metric.compute()\n",
    "        print(f\" mAP@IoU=0.5: {results['map_50']:.4f} | mAP@IoU=0.5:0.95: {results['map']:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"fasterrcnn_pascalvoc.pth\")\n",
    "print(\"Model saved as fasterrcnn_pascalvoc.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b65b42c",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eabc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "🔍 Starting video inference...\n",
      "\n",
      " Inference complete. Output saved to C:\\Users\\anagh\\OneDrive\\Documents\\MAI\\S3\\ACV\\Inference_outputVideo.mp4\n",
      " Processed 2845 frames in 423.72 seconds\n",
      " Average Inference Speed: 6.71 FPS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "\n",
    "CLASSES = [\"__background__\", \"donkey\", \"tortoise\"]\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=None)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, NUM_CLASSES)\n",
    "model.load_state_dict(torch.load(\"fasterrcnn_pascalvoc.pth\", map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "input_path = r\"C:\\Users\\anagh\\OneDrive\\Documents\\MAI\\S3\\ACV\\Inference_Video.mp4\"\n",
    "output_path = r\"C:\\Users\\anagh\\OneDrive\\Documents\\MAI\\S3\\ACV\\Inference_outputVideo.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "CONF_THRESHOLD = 0.5\n",
    "frame_count = 0\n",
    "total_time = 0\n",
    "\n",
    "print(\" Starting video inference...\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Convert to tensor\n",
    "    image_tensor = F.to_tensor(frame).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        prediction = model([image_tensor])[0]\n",
    "\n",
    "    # Draw predictions\n",
    "    for box, score, label in zip(prediction['boxes'], prediction['scores'], prediction['labels']):\n",
    "        if score >= CONF_THRESHOLD:\n",
    "            x1, y1, x2, y2 = box.int().tolist()\n",
    "            class_name = CLASSES[label]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{class_name} {score:.2f}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time += (end_time - start_time)\n",
    "    frame_count += 1\n",
    "\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Summary \n",
    "avg_fps = frame_count / total_time if total_time > 0 else 0\n",
    "print(f\"\\n Inference complete. Output saved to {output_path}\")\n",
    "print(f\" Processed {frame_count} frames in {total_time:.2f} seconds\")\n",
    "print(f\" Average Inference Speed: {avg_fps:.2f} FPS\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
